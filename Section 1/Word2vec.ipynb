{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec\n",
    "## In this notebook we will play with spaCy's word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man man 1.0\n",
      "man woman 0.5783229\n",
      "man king 0.491998\n",
      "man queen 0.09714928\n",
      "woman man 0.5783229\n",
      "woman woman 1.0\n",
      "woman king 0.67171866\n",
      "woman queen 0.34120008\n",
      "king man 0.491998\n",
      "king woman 0.67171866\n",
      "king king 1.0\n",
      "king queen 0.31878188\n",
      "queen man 0.09714928\n",
      "queen woman 0.34120008\n",
      "queen king 0.31878188\n",
      "queen queen 1.0\n"
     ]
    }
   ],
   "source": [
    "example1 = \"man woman king queen\"\n",
    "tokens = nlp(example1)\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walking walked 0.03380737\n",
      "walking swimming 0.46878663\n",
      "walking swam 0.13061452\n",
      "walked walking 0.03380737\n",
      "walked swimming -0.07051619\n",
      "walked swam -0.04058967\n",
      "swimming walking 0.46878663\n",
      "swimming walked -0.07051619\n",
      "swimming swam 0.3709051\n",
      "swam walking 0.13061452\n",
      "swam walked -0.04058967\n",
      "swam swimming 0.3709051\n"
     ]
    }
   ],
   "source": [
    "example1 = \"walking walked swimming swam\"\n",
    "tokens = nlp(example1)\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        if(token1.text == token2.text):\n",
    "            continue\n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spain russia 0.3216639\n",
      "spain madrid 0.51518124\n",
      "spain moscow 0.23857422\n",
      "russia spain 0.3216639\n",
      "russia madrid 0.49487153\n",
      "russia moscow 0.29201046\n",
      "madrid spain 0.51518124\n",
      "madrid russia 0.49487153\n",
      "madrid moscow 0.29396096\n",
      "moscow spain 0.23857422\n",
      "moscow russia 0.29201046\n",
      "moscow madrid 0.29396096\n"
     ]
    }
   ],
   "source": [
    "example1 = \"spain russia madrid moscow\"\n",
    "tokens = nlp(example1)\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        if(token1.text == token2.text):\n",
    "            continue\n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat dog 0.3464731\n",
      "dog cat 0.3464731\n"
     ]
    }
   ],
   "source": [
    "example1 = \"cat dog\"\n",
    "tokens = nlp(example1)\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        if(token1.text == token2.text):\n",
    "            continue        \n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat pizza 0.40963048\n",
      "pizza cat 0.40963048\n"
     ]
    }
   ],
   "source": [
    "example1 = \"cat pizza\"\n",
    "tokens = nlp(example1)\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        if(token1.text == token2.text):\n",
    "            continue        \n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flower pasta 0.51757944\n",
      "pasta flower 0.51757944\n"
     ]
    }
   ],
   "source": [
    "example1 = \"flower pasta\"\n",
    "tokens = nlp(example1)\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        if(token1.text == token2.text):\n",
    "            continue        \n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
